{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GiroE GARMIN fit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fitdecode, os, json\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"GarminRawData\"\n",
    "\n",
    "\n",
    "def decode_fit(dirName, fName):\n",
    "    with fitdecode.FitReader(os.path.join(dirName, fName)) as fit:\n",
    "        for frame in fit:\n",
    "            # The yielded frame object is of one of the following types:\n",
    "            # * fitdecode.FitHeader (FIT_FRAME_HEADER)\n",
    "            # * fitdecode.FitDefinitionMessage (FIT_FRAME_DEFINITION)\n",
    "            # * fitdecode.FitDataMessage (FIT_FRAME_DATA)\n",
    "            # * fitdecode.FitCRC (FIT_FRAME_CRC)\n",
    "\n",
    "            if frame.frame_type == fitdecode.FIT_FRAME_DATA:\n",
    "                # Here, frame is a FitDataMessage object.\n",
    "                # A FitDataMessage object contains decoded values that\n",
    "                # are directly usable in your script logic.\n",
    "                print(frame.name)\n",
    "                if frame.name == \"record\":\n",
    "                    print(\"record\")\n",
    "                else:\n",
    "                    print(\"else\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# for f in $(ls GarminRawData |grep -v .zip)\n",
    "# do \n",
    "#     for fitf in $(ls GarminRawData/$f)\n",
    "#         do\n",
    "#         echo $fitf\n",
    "#         done\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datadir in [os.path.join(DATADIR,d) for d in os.listdir(DATADIR) if not d.endswith('.zip') and not d.startswith('.')]:\n",
    "#     for file in os.listdir(datadir):\n",
    "#         print(os.path.join(datadir,file))\n",
    "#         decode_fit(datadir, file)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No points in GarminRawData/3818/2024-05-05-15-58-25.fit.json\n",
      "No points in GarminRawData/4642/2024-05-25-15-15-05.fit.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse(f):\n",
    "    try:\n",
    "        json_file = f[0]\n",
    "        df = pd.read_json(json_file)\n",
    "        record_df = df.loc[(df[\"frame_type\"] == \"data_message\") & (df.name == \"record\")]\n",
    "        values_df = pd.concat(\n",
    "            [\n",
    "                pd.DataFrame.from_records(l)[[\"name\", \"value\"]]\n",
    "                .set_index(\"name\")\n",
    "                .transpose()\n",
    "                for l in record_df.fields\n",
    "            ]\n",
    "        )\n",
    "        if values_df.shape[0] !=0:\n",
    "            values_df.to_csv(f\"{json_file[:-8]}csv\")\n",
    "            values_df[\"timestamp\"] = pd.to_datetime(values_df[\"timestamp\"])\n",
    "            # values_df.to_excel(f\"{json_file[:-8]}xlsx\")\n",
    "            stats = {}\n",
    "            stats[\"data_filename\"] = json_file\n",
    "            stats[\"t_start\"] = values_df.timestamp.min()\n",
    "            stats[\"t_stop\"] = values_df.timestamp.max()\n",
    "            stats[\"duration_sec\"] = stats[\"t_stop\"] - stats[\"t_start\"]\n",
    "\n",
    "            stats[\"t_start\"] = stats[\"t_start\"].isoformat()\n",
    "            stats[\"t_stop\"] = stats[\"t_stop\"].isoformat()\n",
    "            stats[\"duration_sec\"] = stats[\"duration_sec\"].total_seconds()\n",
    "\n",
    "            stats.update(\n",
    "                pd.DataFrame.from_records(\n",
    "                    df.loc[\n",
    "                        (df.frame_type == \"data_message\") & (df.name == \"file_id\")\n",
    "                    ].fields.values[0]\n",
    "                )[[\"name\", \"value\"]]\n",
    "                .set_index(\"name\")\n",
    "                .to_dict()[\"value\"]\n",
    "            )\n",
    "            with open(f\"{json_file[:-9]}-stat.json\", \"w\") as f:\n",
    "                json.dump(stats, f, indent=2)\n",
    "    except ValueError:\n",
    "        print(f\"No points in {json_file}\")\n",
    "    except KeyError:\n",
    "        print(f\"Empty file {json_file}\")\n",
    "   \n",
    "\n",
    "\n",
    "Parallel(n_jobs=10)(\n",
    "    delayed(parse)(f)\n",
    "    for f in pd.read_csv(\n",
    "        \"/Users/paolo/PycharmProjects/most-garmin-grabber/files.csv\", header=None\n",
    "    ).values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read stat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['./GarminRawData/4141/2024-05-26-12-08-55-stat.json'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('stat.csv', header=None).values[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MOST_flagship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
